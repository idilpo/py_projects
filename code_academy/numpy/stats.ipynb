{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Statistics with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Mean\n",
    "- Median\n",
    "- Percentiles\n",
    "- Interquartile Range\n",
    "- Outliers\n",
    "- Standard Deviation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After the river in your town flooded during a recent hurricane, you've become interested in collecting data about its height.\n",
    "Every day for the past month, you walk to the river, measure the height of the water, and enter this information into a \n",
    "notebook. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_height = np.array([4.01, 4.03, 4.27, 4.29, 4.19,\n",
    "                         4.15, 4.16, 4.23, 4.29, 4.19,\n",
    "                         4.00, 4.22, 4.25, 4.19, 4.10,\n",
    "                         4.14, 4.03, 4.23, 4.08, 14.20,\n",
    "                         14.03, 11.20, 8.19, 6.18, 4.04,\n",
    "                         4.08, 4.11, 4.23, 3.99, 4.23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.251"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.mean:\n",
    "average_height = np.mean(water_height)\n",
    "average_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.99,  4.  ,  4.01,  4.03,  4.03,  4.04,  4.08,  4.08,  4.1 ,\n",
       "        4.11,  4.14,  4.15,  4.16,  4.19,  4.19,  4.19,  4.22,  4.23,\n",
       "        4.23,  4.23,  4.23,  4.25,  4.27,  4.29,  4.29,  6.18,  8.19,\n",
       "       11.2 , 14.03, 14.2 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But wait! We should sort our data to see if there could be any measurements to throw our data off, \n",
    "# or represent a deviation from the mean:\n",
    "np.sort(water_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like that thunderstorm might have impacted the average height! Let's measure the median to see if \n",
    "# its more representative of the dataset:\n",
    "np.median(water_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.265"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# While the median tells us where half of our data lies, let's look at a value closer to the end of the dataset. \n",
    "# We can use percentiles to use a data points position and get its value:\n",
    "np.percentile(water_height, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.784585367099861"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So far, we've gotten a good idea about specific values. But what about the spread of our data? Let's calculate \n",
    "# the standard deviation to understand how similar or how different each data point is:\n",
    "np.std(water_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and logical statements:\n",
    "# when np.mean calculates a logical statement, the resulting mean value will be equivalent to the total number of \n",
    "# True items divided by the total array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Five participants were asked to rate how drowsy the medication made them once a day for three days on a scale of one \n",
    "(least drowsy) to ten (most drowsy). Use np.mean to find the average level of drowsiness across all the trials and save \n",
    "the result to the variable total_mean. Use np.mean to find the average level of drowsiness across each day of the \n",
    "experiment and save to the variable trial_mean. Use np.mean to find the average level of drowsiness across for each \n",
    "individual patient to see if some were more sensitive to the drug than others and save it to the variable patient_mean.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergy_trials = np.array([[6, 1, 3, 8, 2], \n",
    "                           [2, 6, 3, 9, 8], \n",
    "                           [5, 2, 6, 9, 9]])\n",
    "\n",
    "total_mean = np.mean(allergy_trials)\n",
    "trial_mean = np.mean(allergy_trials, axis=1) # mean of rows\n",
    "patient_mean = np.mean(allergy_trials, axis=0) # mean of columns\n",
    "print(trial_mean)\n",
    "print(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "outliers: As we can see, the mean is a helpful way to quickly understand different parts of our data. However, the mean \n",
    "is highly influenced by the specific values in our data set. What happens when one of those values is significantly different\n",
    "from the rest? Values that don’t fit within the majority of a dataset are known as outliers. It’s important to identify \n",
    "outliers because if they go unnoticed, they can skew our data and lead to error in our analysis (like determining the mean). \n",
    "They can also be useful in pointing out errors in our data collection. When we’re able to identify outliers, we can then \n",
    "determine if they were due to an error in sample collection or whether or not they represent a significant but real deviation\n",
    "from the mean.\n",
    "\n",
    "One way to quickly identify outliers is by sorting our data, Once our data is sorted, we can quickly glance at the beginning \n",
    "or end of an array to see if some values lie far beyond the expected range.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median: the middle value of a dataset that’s been ordered in terms of magnitude (from lowest to highest).\n",
    "\n",
    "# Calculate the median, without using Numpy, and save the value to the variable small_set_median:\n",
    "\"\"\"\n",
    "dataset = np.array([10100, 35500, 105000, 85000, 25500, 40500, 65000])\n",
    "sorted_dataset = np.sort(dataset)\n",
    "print(sorted_dataset)\n",
    "small_set_median = sorted_dataset[len(dataset)/2]\n",
    "print(small_set_median)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike a mean, the median is not affected by outliers. This becomes important in skewed datasets, \n",
    "# datasets whose values are not distributed evenly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentiles: As we know, the median is the middle of a dataset - it is the number for which 50% of the samples are below, \n",
    "# and 50% of the samples are above. But what if we wanted to find a point at which 40% of the samples are below, and 60% of \n",
    "# the samples are above? This type of point is called a percentile. The Nth percentile is defined as the point N% of samples \n",
    "# lie below it. So the point where 40% of samples are below is called the 40th percentile. \n",
    "# Percentiles are useful measurements because they can tell us where a particular value is situated within the greater dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([1, 2, 3, 4, 4, 4, 6, 6, 7,  8, 8])\n",
    "np.percentile(d, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 8.0\n"
     ]
    }
   ],
   "source": [
    "patrons = np.array([ 2, 6, 14, 4, 3, 9, 1, 11, 4, 2, 8])\n",
    "\n",
    "thirtieth_percentile = np.percentile(patrons, 30)\n",
    "seventieth_percentile = np.percentile(patrons, 70)\n",
    "print(thirtieth_percentile, seventieth_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some percentiles have specific names:\n",
    "The 25th percentile is called the \"first quartile\"\n",
    "The 50th percentile is called the \"median\"\n",
    "The 75th percentile is called the \"third quartile\"\n",
    "\n",
    "The minimum, first quartile, median, third quartile, and maximum of a dataset are called a five-number summary. This set \n",
    "of numbers is a great thing to compute when we get a new dataset.\n",
    "\n",
    "The difference between the first and third quartile is a value called the interquartile range = thirdP(75) - firstP(25). \n",
    "50% of the dataset will lie within the interquartile range. The interquartile range gives us an idea of \n",
    "how spread out the data is. The smaller the interquartile range value, the less variance in our dataset. \n",
    "The greater the value, the larger the variance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation: While the mean and median can tell us about the center of our data, they do not reflect the range \n",
    "# of the data. That’s where standard deviation comes in. Similar to the interquartile range, the standard deviation tells \n",
    "# us the spread of the data. The larger the standard deviation, the more spread out our data is from the center. \n",
    "# The smaller the standard deviation, the more the data is clustered around the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.716909687891082"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = np.array([65, 36, 52, 91, 63, 79])\n",
    "np.std(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pumpkin: 611.3183785884406 Acorn Squash: 87.22505374031019\n"
     ]
    }
   ],
   "source": [
    "# Find the average weight for each competition and save them to the variables pumpkin_avg and acorn_squash_avg.\n",
    "pumpkin = np.array([68, 1820, 1420, 2062, 704, 1156, 1857, 1755, 2092, 1384])\n",
    "\n",
    "acorn_squash = np.array([20, 43, 99, 200, 12, 250, 58, 120, 230, 215])\n",
    "\n",
    "pumpkin_avg = np.mean(pumpkin)\n",
    "acorn_squash_avg =  np.mean(acorn_squash)\n",
    "\n",
    "# Find how representative the mean values are in relation to the entirety of the submissions. Calculate the standard deviation\n",
    "# for each of the datasets to find and save them to the variables pumpkin_std and acorn_squash_std. \n",
    "# Determine the squash dataset that has the greater standard deviation and save it to the variable winner.\n",
    "pumpkin_std = np.std(pumpkin)\n",
    "acorn_squash_std =  np.std(acorn_squash)\n",
    "\n",
    "print(\"Pumpkin:\", pumpkin_std, \"Acorn Squash:\", acorn_squash_std)\n",
    "winner = pumpkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall = np.array([5.21, 3.76, 3.27, 2.35, 1.89, 1.55, 0.65, 1.06, 1.72, 3.35, 4.82, 5.11])\n",
    "\n",
    "rain_mean = np.mean(rainfall)\n",
    "rain_median = np.median(rainfall)\n",
    "first_quarter = np.percentile(rainfall,25)\n",
    "third_quarter = np.percentile(rainfall,75)\n",
    "interquartile_range = third_quarter - first_quarter\n",
    "rain_std = np.std(rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
